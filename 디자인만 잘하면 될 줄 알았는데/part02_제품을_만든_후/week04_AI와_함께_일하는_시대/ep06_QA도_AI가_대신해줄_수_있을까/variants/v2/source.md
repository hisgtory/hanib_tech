# QA도 AI가 대신해줄 수 있을까 - 실무 체크리스트 버전

<!-- variant: v2, type: 실무 체크리스트 버전 -->

## 핵심 요약

AI는 테스트 케이스 생성, 반복 테스트 자동화, 버그 패턴 분석에 효과적이다. 단, 사용자 경험 판단과 맥락 기반 테스트는 여전히 사람의 영역이다.

---

## AI QA 활용 영역

| 영역 | AI 활용도 | 설명 |
|------|----------|------|
| 테스트 케이스 생성 | ★★★★★ | 요구사항 기반 케이스 자동 생성 |
| 회귀 테스트 | ★★★★★ | 반복 테스트 자동화 |
| UI 테스트 | ★★★★☆ | 스크린샷 비교, 요소 감지 |
| 버그 분류 | ★★★★☆ | 패턴 기반 자동 분류 |
| 탐색적 테스트 | ★★☆☆☆ | 창의적 시나리오 한계 |
| UX 평가 | ★☆☆☆☆ | 주관적 판단 어려움 |

---

## AI QA 도구 분류

| 용도 | 도구 예시 | 특징 |
|------|----------|------|
| 테스트 자동화 | Testim, Mabl | AI 기반 테스트 생성 |
| 시각적 테스트 | Applitools, Percy | 스크린샷 비교 |
| 성능 테스트 | LoadRunner AI | 패턴 기반 부하 예측 |
| 보안 테스트 | Snyk, Checkmarx | 취약점 자동 스캔 |
| 코드 리뷰 | GitHub Copilot | 코드 품질 분석 |

---

## AI 테스트 케이스 생성 체크리스트

### 프롬프트에 포함할 정보
- [ ] 기능 설명
- [ ] 입력값 범위
- [ ] 예상 출력
- [ ] 제약 조건
- [ ] 에러 케이스

### 프롬프트 템플릿
```
아래 기능에 대한 테스트 케이스를 작성해주세요.

[기능]
- 기능명: 로그인
- 입력: 이메일, 비밀번호
- 동작: 인증 후 홈 화면 이동

[테스트 케이스 포함 사항]
1. 정상 케이스
2. 입력값 경계 케이스
3. 에러 케이스
4. 보안 관련 케이스

각 케이스에 대해 테스트 조건, 테스트 데이터,
예상 결과를 표 형식으로 정리해주세요.
```

### 결과 검토
- [ ] 누락된 케이스 확인
- [ ] 경계값 테스트 포함 여부
- [ ] 실제 환경과 맞는지 확인
- [ ] 우선순위 재조정

---

## AI 버그 분석 체크리스트

### 버그 리포트 분석 요청
```
아래 버그 리포트를 분석해주세요.

[버그 정보]
제목: 결제 버튼이 작동하지 않음
환경: iOS 17, Safari
재현 단계: ...
에러 로그: ...

[분석 요청]
1. 예상 원인 3가지
2. 확인해볼 영역
3. 유사 버그 패턴
4. 우선순위 제안
```

### AI 분석 결과 활용
- [ ] 예상 원인 목록 검토
- [ ] 관련 코드 영역 확인
- [ ] 유사 버그 히스토리 대조
- [ ] 개발팀과 공유

---

## QA 단계별 AI 활용

### 1. 계획 단계
| 활동 | AI 활용 방법 |
|------|-------------|
| 테스트 전략 | 리스크 분석, 우선순위 제안 |
| 범위 정의 | 영향 범위 분석 |
| 리소스 산정 | 과거 데이터 기반 예측 |

### 2. 설계 단계
| 활동 | AI 활용 방법 |
|------|-------------|
| 테스트 케이스 | 요구사항 기반 자동 생성 |
| 테스트 데이터 | 다양한 시나리오 데이터 생성 |
| 체크리스트 | 누락 항목 검토 |

### 3. 실행 단계
| 활동 | AI 활용 방법 |
|------|-------------|
| 자동화 테스트 | 스크립트 실행, 결과 분석 |
| 시각적 테스트 | 스크린샷 비교, 차이 감지 |
| 회귀 테스트 | 영향 범위 기반 테스트 선별 |

### 4. 리포트 단계
| 활동 | AI 활용 방법 |
|------|-------------|
| 결과 분석 | 패턴 식별, 트렌드 분석 |
| 버그 분류 | 자동 카테고리화 |
| 리포트 작성 | 요약 및 시각화 |

---

## AI가 잘하는 QA vs 못하는 QA

### AI가 잘하는 것
- [ ] 대량의 테스트 케이스 생성
- [ ] 반복적인 회귀 테스트
- [ ] 스크린샷/UI 비교
- [ ] 로그 분석 및 패턴 감지
- [ ] 성능 데이터 분석
- [ ] 테스트 커버리지 분석

### AI가 못하는 것
- [ ] 사용자 경험 평가
- [ ] 직관적 사용성 판단
- [ ] 비즈니스 맥락 이해
- [ ] 창의적 탐색 테스트
- [ ] 감정/미적 판단
- [ ] 예외 상황 추론

---

## AI QA 도입 체크리스트

### 도입 전 검토
- [ ] 현재 QA 프로세스 파악
- [ ] 자동화 가능 영역 식별
- [ ] 도구 비용 대비 효과
- [ ] 팀 학습 곡선 고려

### 도입 시 주의
- [ ] 점진적 도입 (파일럿 먼저)
- [ ] 기존 프로세스와 통합
- [ ] 결과 검증 프로세스 마련
- [ ] 팀 교육 계획

### 도입 후 모니터링
- [ ] 정확도 측정
- [ ] 시간 절감 효과
- [ ] 발견 버그 품질
- [ ] 팀 만족도

---

## AI QA 한계 인식

### 오탐/미탐 관리
| 유형 | 설명 | 대응 |
|------|------|------|
| False Positive | 버그 아닌데 버그로 판단 | 수동 검증 필요 |
| False Negative | 버그인데 놓침 | 보완 테스트 필요 |

### AI 결과 검증 체크리스트
- [ ] 중요 버그는 수동 재확인
- [ ] AI 판단 근거 검토
- [ ] 오탐 패턴 학습시키기
- [ ] 정기적 정확도 측정

---

## 실무 팁

:::callout[tip]
**"AI는 양, 사람은 질"**

효율적인 분업:
- AI: 대량 테스트, 반복 작업, 데이터 분석
- 사람: UX 판단, 탐색 테스트, 최종 검증

→ AI가 80% 커버, 사람이 20% 핵심 집중
:::

:::callout[warning]
**AI QA의 함정**

주의할 점:
- "AI가 통과했으니 문제없다" 착각
- 테스트 케이스 품질 미검증
- 오탐/미탐 누적
- 사람의 판단력 퇴화

→ AI는 도우미, 최종 판단은 사람
:::

---

## QA 자동화 우선순위

### 자동화 적합 (먼저 적용)
- [ ] 회귀 테스트
- [ ] 스모크 테스트
- [ ] API 테스트
- [ ] 성능 테스트
- [ ] 보안 스캔

### 수동 유지 (사람이 직접)
- [ ] 탐색적 테스트
- [ ] 사용성 테스트
- [ ] 접근성 테스트
- [ ] 새 기능 첫 테스트
- [ ] 복잡한 시나리오

---

## 빠른 체크

| 질문 | 확인 |
|------|------|
| AI QA 도입 목적이 명확한가? | ☐ |
| 자동화할 영역을 선별했는가? | ☐ |
| AI 결과 검증 프로세스가 있는가? | ☐ |
| 사람이 집중할 영역을 정했는가? | ☐ |
